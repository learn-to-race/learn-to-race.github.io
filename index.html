---
layout: home
title: Learn-to-Race
description: Open-source reinforcement learning environment for autonomous racing.
getting_started: https://learn-to-race.readthedocs.io/en/latest/getting_started.html
background: '/img/bg-index-roborace-small.jpeg'
image: 'img/carla.jpg'
---

<script>
function toggleVis(item) {
  var y = item;
  var x = document.getElementById(y);
  if (x.style.display === "none") {
    x.style.display = "block";
  } else {
    x.style.display = "none";
  }
}
</script>

<h3>Introduction</h3>
<p style="margin-top:0px;font-size:18px;">Learn-to-Race is an OpenAI gym compliant, multimodal control environment where agents learn how to race. Unlike many simplistic learning environments, ours is built around Arrival’s high-fidelity racing simulator featuring full software-in-the-loop (SIL), and even hardware-in-the-loop (HIL), simulation capabilities. This simulator has played a key role in bringing autonomous racing technology to real life in the Roborace series, the world’s first extreme competition of teams developing self-driving AI.</p>

<div class="container" style="margin-top:30px;margin-bottom:30px;">
    <img width="700px" height="221px" src="/img/image_overview.png" alt="Learn-to-Race: A Multimodal Control Environment for Autonomous Racing">
</div>

<div class="container" style="margin-top:30px;margin-bottom:30px;">
    <img width="700px" height="233px" src="/img/main_figure.png" alt="Learn-to-Race: A Multimodal Control Environment for Autonomous Racing">
</div>


<h3 style="margin-bottom:15px;">Video</h3>

{% include youtube.html id="2c-KlQ8SFcc" %}


<h3>Selected feature highlights</h3>
<ul>
    <li><strong>High-fidelity racing maps + generation</strong>: the L2R framework and the Arrival Autonomous Racing Simulator offer agents the ability to learn to race on high-precision models of real-world racing tracks, such as the famed Thruxton Circuit (UK) and the North Road Track at the Las Vegas Motor Speedway. Users are also able to construct their own maps, using the map-builder mode.</li>
    <li><strong>Flexible training environment</strong>: We generated a rich, multimodal dataset of expert demonstrations, in order to facilitate various offline learning paradigms, such as imitative modeling, multitask learning, and transfer learning. Our framework provides a realistic simulation environment for online training, as in reinforcement learning.</li>
    <li><strong>Real-world communication protocols</strong>: The simulator provides support for V2V and V2I communication through its V2X subsystem (UDP), with the ability to visualise the received objects and to generate own V2V/V2I stream to the outside world. Additionally, the simulator implements full CAN (Controller Area Network) buses.</li>
    <li><strong>Full control of vehicle sensor suite</strong>: The simulator provides support for RGB, depth, segmentation, GPS, and IMU sensor modalities, as well as the ability to add/remove/edit sensors in real-time, if desired, using the sensors placement mode.</li>
    <li><strong>Full control of vehicle mechanics</strong>: The simulator provides a vehicle builder mode, enabling quick prototyping of new vehicle types, such as the abilities to add/develop/customise (i) the physical vehicle model, (ii) the vehicle mechanical components (steering, braking, motors, differential, transmission, etc.), and (iii) vehicle control units for HIL (hardware in the loop) or SIL (software in the loop) modes.</li>
    <li><strong>Full control of environmental state</strong>: Management of the simulator’s state is done through a web-socket interface, allowing for two-way communication andfor clients to update the state of the simulator including theability to: change the map, change vehicle type and pose, change input mode, toggle debugging routines and sensors, and to modify vehicle and sensor parameters.</li>
    <li><strong>Support for CARLA</strong>: the Arrival Autonomous Racing simulator supports full integration with the CARLA simulator, making it possible to use both simultaneously.</li>
    <li><strong>Autonomous racing baselines</strong>: we provide L2R baselines as runnable agents in CARLA, soft-actor critic, conditional imitation learning, a model-predictive controller.</li>
</ul>

<!--
<h3>CARLA Talks</h3>
<p>The team creates some additional content for users, besides the docs. This is a great way to cover different subjects such as detailed explanations for a specific module, latest improvements in a feature, future work and much more.</p>

<h5>May 2020</h5>
<ul><strong>General</strong>
<li>Art improvements: environment and rendering — <a href="https://youtu.be/ZZaHevsz8W8">video</a> | <a href="https://drive.google.com/file/d/1l9Ztaq0Q8fNN5YPU4-5vL13eZUwsQl5P/view?usp=sharing">slides</a></li>
<li>Core implementations: synchrony, snapshots and landmarks — <a href="https://youtu.be/nyyTLmphqY4">video</a> | <a href="https://drive.google.com/file/d/1yaOwf1419qWZqE1gTSrrknsWOhawEWh_/view?usp=sharing">slides</a></li>
<li>Data ingestion — <a href="https://youtu.be/mHiUUZ4xC9o">video</a> | <a href="https://drive.google.com/file/d/10uNBAMreKajYimIhwCqSYXjhfVs2bX31/view?usp=sharing">slides</a></li>
<li>Pedestrians and their implementation — <a href="https://youtu.be/Uoz2ihDwaWA">video</a> | <a href="https://drive.google.com/file/d/1Tsosin7BLP1k558shtbzUdo2ZXVKy5CB/view?usp=sharing">slides</a></li>
<li>Sensors in CARLA — <a href="https://youtu.be/T8qCSet8WK0">video</a> | <a href="https://drive.google.com/file/d/1UO8ZAIOp-1xaBzcFMfn_IoipycVkUo4q/view?usp=sharing">slides</a></li>
</ul>
<ul><strong>Modules</strong>
<li>Improvements in the Traffic Manager — <a href="https://youtu.be/n9cufaJ17eA">video</a> | <a href="https://drive.google.com/file/d/1R9uNZ6pYHSZoEBxs2vYK7swiriKbbuxo/view?usp=sharing">slides</a></li>
<li>Integration of autoware and ROS — <a href="https://youtu.be/ChIgcC2scwU">video</a> | <a href="https://drive.google.com/file/d/1uO6nBaFirrllb08OeqGAMVLApQ6EbgAt/view?usp=sharing">slides</a></li>
<li>Introducing ScenarioRunner — <a href="https://youtu.be/dcnnNJowqzM">video</a> | <a href="https://drive.google.com/file/d/1zgoH_kLOfIw117FJGm2IVZZAIRw9U2Q0/view?usp=sharing">slides</a></li>
<li>OpenSCENARIO support — <a href="https://drive.google.com/file/d/1g6ATxZRTWEdstiZwfBN1_T_x_WwZs0zE/view?usp=sharing">slides</a></li>
</ul>
<ul><strong>Features</strong>
<li>Co-Simulations with SUMO and PTV-Vissim — <a href="https://youtu.be/PuFSbj1PU94">video</a> | <a href="https://drive.google.com/file/d/10DgMNUBqKqWBrdiwBiAIT4DdR9ObCquI/view?usp=sharing">slides</a></li>
<li>Integration of RSS-lib — <a href="https://drive.google.com/file/d/1whREmrCv67fOMipgCk6kkiW4VPODig0A/view?usp=sharing">slides</a></li>
<li>The External Sensor Interface (ESI) — <a href="https://youtu.be/5hXHPV9FIeY">video</a> | <a href="https://drive.google.com/file/d/1VWFaEoS12siW6NtQDUkm44BVO7tveRbJ/view?usp=sharing">slides</a></li>
<li>The OpenDRIVE Standalone Mode — <a href="https://youtu.be/U25GhofVV1Q">video</a> | <a href="https://drive.google.com/file/d/1D5VsgfX7dmgPWn7UtDDid3-OdS1HI4pY/view?usp=sharing">slides</a></li>
</ul>
-->

<h3>Papers</h3>

<div class="container" style="margin-top:30px;margin-bottom:30px;">
    <p style="margin:0 0 4px 0;font-size:18px;">Learn-to-Race: A Multimodal Control Environment for Autonomous Racing</p>
    <p style="margin:0 0 2px 0;font-size:14px;color:#000000;">James Herman, Jonathan Francis, Siddha Ganju, Bingqing Chen, Anirudh Koul, Abhinav Gupta, Alexey Skabelkin, Ivan Zhukov, Max Kumskoy, Eric Nyberg</p>
    <p style="margin:0 0 20px 0;font-size:14px;color:#000000;">ICCV 2021 [<a href="javascript:void(0)" onclick='toggleVis("bibtex1")'>Bibtex</a>] [<a href="https://arxiv.org/pdf/2103.11575.pdf">PDF</a>] [<a href="https://github.com/learn-to-race/l2r">Code</a>]</p>

    <div id="bibtex1" style="display:none;background:#EEE;margin:0px;padding:0px;">
        <pre><code class="pre-scrollable" style="color:#333;font-size:12px;">
          @misc{herman2021learntorace,
          title={Learn-to-Race: A Multimodal Control Environment for Autonomous Racing},
          author={James Herman and Jonathan Francis and Siddha Ganju and Bingqing Chen and Anirudh Koul and Abhinav Gupta and Alexey Skabelkin and Ivan Zhukov and Andrey Gostev and Max Kumskoy and Eric Nyberg},
          year={2021},
          eprint={2103.11575},
          archivePrefix={arXiv},
          primaryClass={cs.RO}}
        </code></pre>
    </div>

    <!-- <p id="bibtex1" style="display:none;margin:0 0 20px 0;font-size:14px;color:#000000;">Bibtex</p> -->
    <a href="https://arxiv.org/pdf/2103.11575.pdf">
        <img width="800px" height="297px" src="/img/papers/l2r_main_paper.png" alt="Learn-to-Race: A Multimodal Control Environment for Autonomous Racing">
    </a>
</div>

<div class="container" style="margin-top:30px;margin-bottom:30px;">
    <p style="margin:0 0 4px 0;font-size:18px;">Safety-aware Policy Optimisation for Autonomous Racing</p>
    <p style="margin:0 0 2px 0;font-size:14px;color:#000000;">Bingqing Chen, Jonathan Francis, James Herman, Jean Oh, Eric Nyberg, Sylvia L. Herbert</p>
    <p style="margin:0 0 20px 0;font-size:14px;color:#000000;">Coming soon! [<a href="javascript:void(0)" onclick='toggleVis("bibtex2")'>Bibtex</a>] [<a href="javascript:void(0)">PDF</a>] [<a href="javascript:void(0)">Code</a>]</p>

    <div id="bibtex2" style="display:none;background:#EEE;margin:0px;padding:0px;">
        <pre><code class="pre-scrollable" style="color:#333;font-size:12px;">
          Coming soon!
        </code></pre>
    </div>

    <!-- <p id="bibtex1" style="display:none;margin:0 0 20px 0;font-size:14px;color:#000000;">Bibtex</p> -->
    <a href="javascript:void(0)">
        <img width="800px" height="297px" src="/img/papers/safepo_paper.png" alt="Safety-aware Policy Optimisationfor Autonomous Racing">
    </a>
</div>


<!--
<div class="container" style="margin-top:30px;margin-bottom:30px;">
	<div class="row">
    <div class="col-lg-4" style="padding:0;">
			<h3>Paper</h3>
			<a href="http://proceedings.mlr.press/v78/dosovitskiy17a/dosovitskiy17a.pdf">
				<img src="/img/paper.png" alt="CARLA: An Open Urban Driving Simulator">
			</a>
		</div>
		<div class="col-lg-8" style="padding:0;">
			<h3>BiBTex</h3>
			<div style="background:#EEE;margin:0px;padding:0px;">
				<pre><code class="pre-scrollable" style="color:#333;font-size:12px;">@inproceedings{Dosovitskiy17,
  title = { {CARLA}: {An} Open Urban Driving Simulator},
  author = {Alexey Dosovitskiy and German Ros and Felipe Codevilla and Antonio Lopez and Vladlen Koltun},
  booktitle = {Proceedings of the 1st Annual Conference on Robot Learning},
  pages = {1--16},
  year = {2017}
}</code></pre>
			</div>
		</div>
	</div>
</div>
-->

<div style="display: inline-grid; grid-gap: 25px;" class="grid-container">
	<div style="grid-column: 1;">
		<p><strong>Do you like the project? Star us on GitHub to support the project!</strong></p>
	</div>
	<div style="grid-column: 2; margin-top:25px;" >
		<iframe src="https://ghbtns.com/github-btn.html?user=learn-to-race&repo=l2r&type=star&count=false&size=large" frameborder="0" scrolling="0" width="160px" height="30px"></iframe>
	</div>
</div>
