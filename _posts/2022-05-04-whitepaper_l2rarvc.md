---
layout: post
comments: false
title:  "New white paper posted: The L2R Autonomous Racing Virtual Challenge"
subtitle: "New white paper describes the inaugural instance of the Learn-to-Race Autonomous Racing Virtual Challenge."
description: "New white paper describes the inaugural instance of the Learn-to-Race Autonomous Racing Virtual Challenge."
author: "@jonfranc"
date:   2022-05-04 17:56:58 +0004
background: '/img/posts/2021-12-07/l2r_banner2.png'
---

<div class="container" style="margin-top:30px;margin-bottom:30px;">
    <p style="margin:0 0 4px 0;font-size:18px;">(White Paper) Learn-to-Race Challenge 2022: Benchmarking Safe Learning and Cross-domain Generalisation in Autonomous Racing</p>
    <p style="margin:0 0 2px 0;font-size:14px;color:#000000;">Jonathan Francis*, Bingqing Chen*, Siddha Ganju*, Sidharth Kathpal*, Jyotish Poonganam*, Ayush Shivani*, Sahika Genc, Ivan Zhukov, Max Kumskoy, Jean Oh, Eric Nyberg, Sylvia L. Herbert</p>
    <p style="margin:0 0 20px 0;font-size:14px;color:#000000;">arXiv 2022 [<a href="javascript:void(0)" onclick='toggleVis("bibtex3")'>Bibtex</a>] [<a target="_blank" href="https://arxiv.org/pdf/2205.02953.pdf">PDF</a>]</p>

    <p style="margin:0 0 20px 0;font-size:14px;color:#000000;">We present the results of our new autonomous racing virtual challenge, predicated on the high-fidelity Learn-to-Race (L2R) simulation framework, which seeks to encourage interdisciplinary research in autonomous driving and to help advance state-of-the-art on a practical benchmark. The main goal of the challenge is to evaluate the joint safety, performance, and generalization capabilities of perception and control algorithms, in autonomous racing. Analogous to racing being used to test cutting-edge vehicle technology, we envision autonomous racing to serve as a particularly challenging proving ground for safe learning algorithms as: (i) vehicles are required to drive at their physical limits, with barely any margin for safety, where any infraction could lead to catastrophic failure; (ii) autonomous agents are required to make sub-second decisions, in fast-changing environments; and (iii) visual perception pipelines must remain robust to distribution shifts, novel road features, and other obstacles, in order to facilitate cross-domain safety and performance. In this paper, we describe the new L2R Task 2.0 benchmark, with new metrics and baseline approaches. We also provide an overview of deployment, evaluation, and rankings for the inaugural instance of the L2R Autonomous Racing Virtual Challenge (supported by Carnegie Mellon University, Arrival Ltd., AICrowd, Amazon Web Services, and Honda Research), which officially used the new L2R Task 2.0 benchmark and received over 20,100 views, 437 active participants, 46 teams, and 733 model submissionsâ€”from 88+ unique institutions, in 58+ different countries. Finally, we release leaderboard results from the challenge and provide description of the two top-ranking approaches in cross-domain model transfer, across multiple sensor configurations and simulated races.</p>

    <div id="bibtex3" style="display:block;background:#EEE;margin:0px;padding:0px;">
        <pre><code class="pre-scrollable" style="color:#333;font-size:12px;">
            @misc{francis2022l2rarcv,
                  title={Learn-to-Race Challenge 2022: Benchmarking Safe Learning and Cross-domain Generalisation in Autonomous Racing},
                  author={Jonathan Francis and Bingqing Chen and Siddha Ganju and Sidharth Kathpal and Jyotish Poonganam and Ayush Shivani and Vrushank Vyas and Sahika Genc and Ivan Zhukov and Max Kumskoy and Jean Oh and Eric Nyberg and Sylvia L. Herbert},
                  year={2022},
                  eprint={2205.02953},
                  archivePrefix={arXiv},
                  primaryClass={cs.RO}
            }
        </code></pre>
    </div>
